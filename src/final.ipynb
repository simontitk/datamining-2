{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Project II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from enum import IntEnum\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error, mean_absolute_error, mean_squared_error, accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR 2022\n",
      "features: 637\n",
      "entries: 27651\n",
      "YEAR 2023\n",
      "features: 647\n",
      "entries: 29522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['weight',\n",
       " 'height',\n",
       " 'pregnant',\n",
       " 'age',\n",
       " 'gender',\n",
       " 'education',\n",
       " 'single',\n",
       " 'owns_home',\n",
       " 'parent',\n",
       " 'depression',\n",
       " 'anxiety',\n",
       " 'poverty',\n",
       " 'health_status',\n",
       " 'life_sat',\n",
       " 'insurance',\n",
       " 'living_area',\n",
       " 'region',\n",
       " 'cancer',\n",
       " 'hypertension',\n",
       " 'cholesterol',\n",
       " 'asthma',\n",
       " 'race',\n",
       " 'medical_bill_worry']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = {\n",
    "    \"WEIGHTLBTC_A\": \"weight\", #pounds\n",
    "    \"HEIGHTTC_A\": \"height\", #inches\n",
    "    \"PREGNOW_A\": \"pregnant\",\n",
    "    \"AGEP_A\": \"age\",\n",
    "    \"SEX_A\": \"gender\",\n",
    "    \"EDUCP_A\": \"education\",\n",
    "    \"MARITAL_A\": \"single\",\n",
    "    \"HOUTENURE_A\": \"owns_home\",\n",
    "    \"PARSTAT_A\": \"parent\",\n",
    "    \"DEPFREQ_A\": \"depression\",\n",
    "    \"ANXFREQ_A\": \"anxiety\",\n",
    "    \"POVRATTC_A\": \"poverty\",\n",
    "    \"PHSTAT_A\": \"health_status\",\n",
    "    \"LSATIS4_A\": \"life_sat\",\n",
    "    #\"DRK12MN_A\": \"alcohol\",\n",
    "    #\"SLPHOURS_A\": \"sleep\",\n",
    "    \"NOTCOV_A\": \"insurance\",\n",
    "    \"URBRRL\": \"living_area\",\n",
    "    \"REGION\": \"region\",\n",
    "    \"CANEV_A\": \"cancer\",\n",
    "    \"HYPEV_A\": \"hypertension\",\n",
    "    \"CHLEV_A\": \"cholesterol\",\n",
    "    \"ASEV_A\": \"asthma\",\n",
    "    \"RACEALLP_A\": \"race\",\n",
    "    \"PAYWORRY_A\": \"medical_bill_worry\"\n",
    "}\n",
    "\n",
    "dataframes = []\n",
    "for i in [2, 3]:\n",
    "    df = pd.read_csv(f\"../data/adult2{i}.csv\", sep=\",\")\n",
    "    dataframes.append(df)\n",
    "    print(f\"YEAR 202{i}\\nfeatures: {len(df.columns)}\\nentries: {len(df)}\")\n",
    "    for attr in attributes.keys():\n",
    "        try:\n",
    "            (f\"{attr}: {df[attr].unique()[:(min(10, len(df[attr].unique())))]}\")\n",
    "        except:\n",
    "            print(f\"missing {attr} for 202{i}\")\n",
    "df = pd.concat(dataframes)\n",
    "df = df.loc[:, list(attributes.keys())]\n",
    "df.rename(mapper=attributes, inplace=True, axis=1)\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>single</th>\n",
       "      <th>owns_home</th>\n",
       "      <th>parent</th>\n",
       "      <th>depression</th>\n",
       "      <th>...</th>\n",
       "      <th>life_sat</th>\n",
       "      <th>insurance</th>\n",
       "      <th>living_area</th>\n",
       "      <th>region</th>\n",
       "      <th>cancer</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>asthma</th>\n",
       "      <th>race</th>\n",
       "      <th>medical_bill_worry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>235</td>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>218</td>\n",
       "      <td>69</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29517</th>\n",
       "      <td>190</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29518</th>\n",
       "      <td>165</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29519</th>\n",
       "      <td>220</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29520</th>\n",
       "      <td>170</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29521</th>\n",
       "      <td>155</td>\n",
       "      <td>67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57173 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       weight  height  pregnant  age  gender  education  single  owns_home  \\\n",
       "0         148      68       NaN   85       1          4       3          1   \n",
       "1         235      74       NaN   64       1          8       1          1   \n",
       "2         218      69       2.0   37       2          8       1          1   \n",
       "3         240      64       NaN   72       2          5       2          1   \n",
       "4         183      66       NaN   84       2          6       3          1   \n",
       "...       ...     ...       ...  ...     ...        ...     ...        ...   \n",
       "29517     190      61       NaN   77       2          5       3          1   \n",
       "29518     165      65       NaN   59       2          7       1          1   \n",
       "29519     220      66       NaN   66       1          8       1          1   \n",
       "29520     170      65       NaN   53       2          7       1          1   \n",
       "29521     155      67       NaN   72       2          8       1          1   \n",
       "\n",
       "       parent  depression  ...  life_sat  insurance  living_area  region  \\\n",
       "0           3           5  ...         2          2            2       3   \n",
       "1           3           5  ...         2          2            4       3   \n",
       "2           3           4  ...         1          2            4       3   \n",
       "3           3           5  ...         1          2            4       3   \n",
       "4           3           5  ...         2          2            1       3   \n",
       "...       ...         ...  ...       ...        ...          ...     ...   \n",
       "29517       3           3  ...         2          2            4       4   \n",
       "29518       3           4  ...         1          2            4       4   \n",
       "29519       3           4  ...         2          2            4       4   \n",
       "29520       3           5  ...         1          2            4       4   \n",
       "29521       3           5  ...         1          2            4       4   \n",
       "\n",
       "       cancer  hypertension  cholesterol  asthma  race  medical_bill_worry  \n",
       "0           2             1            2       2     1                   3  \n",
       "1           1             1            1       2     1                   3  \n",
       "2           2             2            2       1     1                   3  \n",
       "3           2             1            2       1     1                   3  \n",
       "4           2             1            2       2     2                   2  \n",
       "...       ...           ...          ...     ...   ...                 ...  \n",
       "29517       2             1            1       1     1                   2  \n",
       "29518       2             2            1       2     1                   3  \n",
       "29519       2             2            2       1     1                   2  \n",
       "29520       2             1            2       1     1                   3  \n",
       "29521       2             1            1       1     1                   3  \n",
       "\n",
       "[57173 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"weight\"] <= 299]\n",
    "df = df[df[\"height\"] <= 76]\n",
    "df = df[((df[\"pregnant\"] == 2) | (df[\"gender\"] == 1))]\n",
    "df = df[df[\"age\"] <= 84]\n",
    "df = df[df[\"gender\"] <= 2]\n",
    "df = df[df[\"education\"] <= 10]\n",
    "df = df[df[\"single\"] <= 3]\n",
    "df = df[df[\"owns_home\"] <= 3]\n",
    "df = df[df[\"parent\"] <= 3]\n",
    "df = df[df[\"depression\"] <= 5]\n",
    "df = df[df[\"anxiety\"] <= 5]\n",
    "df = df[df[\"poverty\"] < 11]\n",
    "df = df[df[\"health_status\"] < 6]\n",
    "df = df[df[\"life_sat\"] < 5]\n",
    "#df = df[df[\"alcohol\"] < 366]\n",
    "#df = df[df[\"sleep\"] < 25]\n",
    "df = df[df[\"insurance\"] <= 2]\n",
    "# living area is good as it is\n",
    "# region too\n",
    "df = df[df[\"cancer\"] <= 2]\n",
    "df = df[df[\"hypertension\"] <= 2]\n",
    "df = df[df[\"cholesterol\"] <= 2]\n",
    "df = df[df[\"asthma\"] <= 2]\n",
    "df = df[df[\"race\"] <= 6]\n",
    "df = df[df[\"medical_bill_worry\"] <= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI calculation\n",
    "POUND_TO_KG = 0.453592\n",
    "INCH_TO_M = 0.0254\n",
    "df[\"weight\"] = df[\"weight\"] * POUND_TO_KG\n",
    "df[\"height\"] = df[\"height\"] * INCH_TO_M\n",
    "df[\"bmi\"] = df[\"weight\"] / df[\"height\"] ** 2\n",
    "\n",
    "del df[\"weight\"]\n",
    "del df[\"height\"]\n",
    "del df[\"pregnant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_cluster_number(df: pd.DataFrame, feature: str, k_number: int) -> int:\n",
    "    inertia = []\n",
    "    k_values = np.arange(1, k_number+1)\n",
    "\n",
    "    for k in k_values:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(df[[feature]])\n",
    "        inertia.append(kmeans.inertia_)\n",
    "\n",
    "    knee_locator = KneeLocator(k_values, inertia, curve='convex', direction='decreasing')\n",
    "    k = knee_locator.knee\n",
    "\n",
    "\n",
    "    \"\"\"fig, ax = plt.subplots(1, figsize=(8, 6))\n",
    "    ax.plot(k_values, inertia, marker='o')\n",
    "    ax.set(xlabel='Number of clusters (k)', ylabel='Inertia', title=f'Elbow Method for Optimal k for {feature}')\n",
    "    ax.axvline(x=elbow_point, c=\"red\")\n",
    "    ax.set_xticks(k_values) \"\"\"\n",
    "\n",
    "    return k, k_values, inertia\n",
    "\n",
    "def plot_cluster(df: pd.DataFrame, feature:str, k_values: np.ndarray, inertia: np.ndarray, k: int):\n",
    "    fig, axs = plt.subplots(2, figsize=(8, 6))\n",
    "    axs[0].plot(k_values, inertia, marker='o')\n",
    "    axs[0].set(xlabel='Number of clusters (k)', ylabel='Inertia', title=f'Elbow Method for Optimal k for {feature}')\n",
    "    axs[0].axvline(x=k, c=\"red\")\n",
    "    axs[0].set_xticks(k_values)\n",
    "\n",
    "    axs[1].scatter(df[feature], df[f'{feature}_cat'], c=df[f'{feature}_cat'], cmap='viridis')\n",
    "    axs[1].set_title(f\"{feature} Categories using K-Means Clustering\")\n",
    "    axs[1].set_xlabel(feature)\n",
    "    axs[1].set_ylabel(\"Category\")\n",
    "\n",
    "    \n",
    "CONTINUOUS_FEATURES = [\"age\", \"bmi\", \"poverty\"]\n",
    "for feature in CONTINUOUS_FEATURES:\n",
    "    k, k_values, inertia = get_optimal_cluster_number(df, feature, 10)\n",
    "    kmeans = KMeans(n_clusters=k, n_init=5, random_state=42)\n",
    "    df[f\"{feature}_cat\"] = kmeans.fit_predict(df[[feature]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regrouping\n",
    "\n",
    "\"\"\"\n",
    "EDUCATION\n",
    "00 (no edu), 01 (no hs), 02 (no diploma): no_hs\n",
    "03 (ged), 04 (hs), 05 (no deg): highschool\n",
    "06 (occupational deg), 07 (academic deg), 08 (bsc): bachelor\n",
    "09 (msc): masters\n",
    "10 (phd): phd\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "MARITAL status:\n",
    "03: single\n",
    "01 (married) 2 (cohabiting): not\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "parent\n",
    "01: parent\n",
    "02 (in famility but not) 03 (not in family): not\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def invert_encoding_order(df: pd.DataFrame, feature: str) -> None:\n",
    "    \"\"\"Reorders the encoding of a categorical variable, \n",
    "    so that the lowest values are encoded 0 and higher ones ascending from here.\"\"\"\n",
    "    df[feature] = df[feature].max() - df[feature]\n",
    "\n",
    "def offset_encoding_to_zero(df: pd.DataFrame, feature: str) -> None:\n",
    "    \"\"\"Re-encodes `1` and `2` category labels into `0` and `1`\"\"\"\n",
    "    df[feature] = df[feature] - 1\n",
    "\n",
    "\n",
    "offset_encoding_to_zero(df, \"gender\") \n",
    "\n",
    "class EduLevel(IntEnum):\n",
    "    NO_HIGHSCHOOL = 0\n",
    "    HIGHSCHOOL = 1\n",
    "    BACHELORS = 2\n",
    "    MASTERS = 3\n",
    "    PHD = 4\n",
    "    \n",
    "df[\"education\"] = df[\"education\"].replace({\n",
    "    1: EduLevel.NO_HIGHSCHOOL,\n",
    "    2: EduLevel.NO_HIGHSCHOOL,\n",
    "    3: EduLevel.HIGHSCHOOL,\n",
    "    4: EduLevel.HIGHSCHOOL,\n",
    "    5: EduLevel.HIGHSCHOOL,\n",
    "    6: EduLevel.BACHELORS,\n",
    "    7: EduLevel.BACHELORS,\n",
    "    8: EduLevel.BACHELORS,\n",
    "    9: EduLevel.MASTERS,\n",
    "    10: EduLevel.PHD\n",
    "})\n",
    "\n",
    "df[\"single\"] = df[\"single\"].replace({\n",
    "    1: 0,\n",
    "    2: 0,\n",
    "    3: 1\n",
    "})\n",
    "\n",
    "df[\"owns_home\"] = df[\"owns_home\"].replace({\n",
    "    1: 1,\n",
    "    2: 0,\n",
    "    3: 0,\n",
    "})\n",
    "\n",
    "df[\"parent\"] = df[\"parent\"].replace({\n",
    "    1: 1,\n",
    "    2: 0,\n",
    "    3: 0\n",
    "})\n",
    "\n",
    "\n",
    "invert_encoding_order(df, \"depression\")\n",
    "\n",
    "invert_encoding_order(df, \"anxiety\")\n",
    "\n",
    "invert_encoding_order(df, \"health_status\")\n",
    "\n",
    "invert_encoding_order(df, \"life_sat\")\n",
    "\n",
    "offset_encoding_to_zero(df, \"insurance\") \n",
    "\n",
    "invert_encoding_order(df, \"living_area\")\n",
    "\n",
    "offset_encoding_to_zero(df, \"region\") \n",
    "\n",
    "invert_encoding_order(df, \"cancer\")\n",
    "\n",
    "invert_encoding_order(df, \"hypertension\")\n",
    "\n",
    "invert_encoding_order(df, \"cholesterol\")\n",
    "\n",
    "invert_encoding_order(df, \"asthma\")\n",
    "\n",
    "offset_encoding_to_zero(df, \"race\") \n",
    "\n",
    "invert_encoding_order(df, \"medical_bill_worry\")\n",
    "\n",
    "df[\"age_cat\"] = df[\"age_cat\"].replace({\n",
    "    1: 0,\n",
    "    2: 1,\n",
    "    0: 2,\n",
    "})\n",
    "\n",
    "df[\"bmi_cat\"] = df[\"bmi_cat\"].replace({\n",
    "    2: 0,\n",
    "    0: 1,\n",
    "    1: 2,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(CONTINUOUS_FEATURES, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crosstables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' target = \"anxiety\"\\n\\nfor f in df.columns.values:\\n    tab = pd.crosstab(df[f], df[target], normalize=\"index\") * 100\\n    plt.figure(figsize=(6, 3))\\n    sns.heatmap(tab, fmt=\\'.2f\\', cmap=\\'coolwarm\\', annot=True)\\n    plt.show() '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" target = \"anxiety\"\n",
    "\n",
    "for f in df.columns.values:\n",
    "    tab = pd.crosstab(df[f], df[target], normalize=\"index\") * 100\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    sns.heatmap(tab, fmt='.2f', cmap='coolwarm', annot=True)\n",
    "    plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-square tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               feature           chi              p\n",
      "0           depression  15793.186491   0.000000e+00\n",
      "1              age_cat   1425.727603  1.823056e-307\n",
      "2   medical_bill_worry   1251.239725  1.240938e-269\n",
      "3               gender   1104.225585  9.189134e-238\n",
      "4        health_status    361.803253   4.957452e-77\n",
      "5               asthma    360.400786   9.956869e-77\n",
      "6             life_sat    345.419779   1.709514e-73\n",
      "7            education    198.090764   9.667944e-42\n",
      "8         hypertension    178.677826   1.433765e-37\n",
      "9            owns_home    155.439801   1.389187e-32\n",
      "10         poverty_cat    136.038180   1.989087e-28\n",
      "11              single    119.390361   7.208863e-25\n",
      "12         cholesterol    107.485402   2.501311e-22\n",
      "13              parent     99.974694   9.959406e-21\n",
      "14              cancer     98.369083   2.187737e-20\n",
      "15         living_area     66.011423   1.575264e-13\n",
      "16             bmi_cat     62.934506   7.004726e-13\n",
      "17                race     39.362905   5.861853e-08\n",
      "18           insurance      1.305928   8.603690e-01\n",
      "19              region      0.927628   9.205641e-01\n"
     ]
    }
   ],
   "source": [
    "X = df.drop([\"anxiety\"], axis=1)\n",
    "y = df['anxiety']\n",
    "\n",
    "chi2_scores, p_values = chi2(X, y)\n",
    "alpha = 0.05\n",
    "\n",
    "feature_names = X.columns\n",
    "results = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'chi': chi2_scores,\n",
    "    'p': p_values\n",
    "}).sort_values(by='p', ignore_index=True)\n",
    "\n",
    "print(results)\n",
    "\n",
    "significant_features = results[results[\"p\"] < alpha][\"feature\"].values\n",
    "insignificant_features =  results[results[\"p\"] >= alpha][\"feature\"].values\n",
    "\n",
    "df.drop(insignificant_features, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>single</th>\n",
       "      <th>owns_home</th>\n",
       "      <th>parent</th>\n",
       "      <th>depression</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>health_status</th>\n",
       "      <th>life_sat</th>\n",
       "      <th>living_area</th>\n",
       "      <th>cancer</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>asthma</th>\n",
       "      <th>race</th>\n",
       "      <th>medical_bill_worry</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>bmi_cat</th>\n",
       "      <th>poverty_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29513</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29514</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29515</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29516</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29519</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28088 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender  education  single  owns_home  parent  depression  anxiety  \\\n",
       "1           0          2       0          1       0           0        1   \n",
       "2           1          2       0          1       0           1        2   \n",
       "10          0          1       1          1       0           1        1   \n",
       "11          0          1       1          1       0           0        0   \n",
       "15          1          1       1          0       1           4        4   \n",
       "...       ...        ...     ...        ...     ...         ...      ...   \n",
       "29513       1          2       1          0       0           2        3   \n",
       "29514       1          3       0          1       1           1        2   \n",
       "29515       0          2       0          1       1           0        2   \n",
       "29516       1          3       1          1       1           0        3   \n",
       "29519       0          2       0          1       0           1        3   \n",
       "\n",
       "       health_status  life_sat  living_area  cancer  hypertension  \\\n",
       "1                  2         2            0       1             1   \n",
       "2                  2         3            0       0             0   \n",
       "10                 2         2            3       1             0   \n",
       "11                 4         3            3       0             0   \n",
       "15                 2         1            0       0             1   \n",
       "...              ...       ...          ...     ...           ...   \n",
       "29513              2         2            1       0             0   \n",
       "29514              4         3            1       0             0   \n",
       "29515              3         3            1       0             0   \n",
       "29516              2         3            0       0             0   \n",
       "29519              2         2            0       0             0   \n",
       "\n",
       "       cholesterol  asthma  race  medical_bill_worry  age_cat  bmi_cat  \\\n",
       "1                1       0     0                   0        2        0   \n",
       "2                0       1     0                   0        1        0   \n",
       "10               1       0     0                   0        2        0   \n",
       "11               1       0     0                   0        2        0   \n",
       "15               0       0     0                   1        0        0   \n",
       "...            ...     ...   ...                 ...      ...      ...   \n",
       "29513            0       1     0                   1        0        0   \n",
       "29514            0       0     0                   1        0        0   \n",
       "29515            0       0     0                   0        1        1   \n",
       "29516            0       0     0                   2        1        0   \n",
       "29519            0       1     0                   1        2        2   \n",
       "\n",
       "       poverty_cat  \n",
       "1                1  \n",
       "2                1  \n",
       "10               2  \n",
       "11               0  \n",
       "15               2  \n",
       "...            ...  \n",
       "29513            0  \n",
       "29514            1  \n",
       "29515            2  \n",
       "29516            0  \n",
       "29519            1  \n",
       "\n",
       "[28088 rows x 19 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_columns = [column for column in significant_features if len(df[column].unique()) > 2] \n",
    "df = pd.get_dummies(df, columns=one_hot_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive\\Dokumenti\\ITU\\III.semester\\DAMIN\\Assignments Git Repository\\datamining-2\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "620 fits failed out of a total of 2500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "620 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\OneDrive\\Dokumenti\\ITU\\III.semester\\DAMIN\\Assignments Git Repository\\datamining-2\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\OneDrive\\Dokumenti\\ITU\\III.semester\\DAMIN\\Assignments Git Repository\\datamining-2\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\OneDrive\\Dokumenti\\ITU\\III.semester\\DAMIN\\Assignments Git Repository\\datamining-2\\.venv\\Lib\\site-packages\\imblearn\\pipeline.py\", line 333, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n",
      "  File \"d:\\OneDrive\\Dokumenti\\ITU\\III.semester\\DAMIN\\Assignments Git Repository\\datamining-2\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\OneDrive\\Dokumenti\\ITU\\III.semester\\DAMIN\\Assignments Git Repository\\datamining-2\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\OneDrive\\Dokumenti\\ITU\\III.semester\\DAMIN\\Assignments Git Repository\\datamining-2\\.venv\\Lib\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "d:\\OneDrive\\Dokumenti\\ITU\\III.semester\\DAMIN\\Assignments Git Repository\\datamining-2\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.38241222 0.40523634 0.39604952 0.4157954  0.40010743 0.39846015\n",
      "        nan 0.41469767 0.36858818 0.4163658  0.35555811 0.34414951\n",
      " 0.41723555        nan 0.35226316 0.38987642 0.40269342 0.41849963\n",
      "        nan        nan        nan 0.39789489        nan 0.41616641\n",
      " 0.36997524 0.41635018 0.40267466 0.40073498 0.40849158 0.41079077\n",
      " 0.40640822 0.4051716  0.41292811        nan        nan 0.41077339\n",
      " 0.41230778 0.41785362 0.3702023  0.41273774 0.41800245 0.42041037\n",
      " 0.41477528        nan        nan 0.41457786 0.40809053 0.40725734\n",
      " 0.41205013        nan 0.39361406 0.41722806 0.40764059 0.41418467\n",
      " 0.410829   0.41603428 0.41393897 0.40664478 0.4131153  0.41194215\n",
      " 0.39581402 0.39137868 0.40332056        nan 0.40888687 0.41407479\n",
      "        nan        nan 0.39334726 0.40991719 0.4160779  0.40853542\n",
      " 0.41479369 0.39054609 0.40943926        nan 0.40450433        nan\n",
      "        nan 0.40907451 0.40481971 0.41071726 0.41044936 0.41636556\n",
      " 0.41304348        nan 0.40165971 0.38475958 0.41441997        nan\n",
      " 0.41264198 0.41673936 0.40637108 0.41743949 0.41553038        nan\n",
      " 0.40579633 0.41719881        nan        nan 0.41862616 0.40142158\n",
      " 0.3960771  0.41524355        nan 0.41571169 0.40099933        nan\n",
      " 0.39542978 0.41697045 0.41564032        nan        nan        nan\n",
      " 0.41709265        nan        nan        nan 0.3995474  0.40155952\n",
      "        nan 0.40558234 0.40539663 0.39167842 0.41243832 0.37332023\n",
      " 0.41531021        nan 0.39871658        nan        nan        nan\n",
      " 0.41016537 0.40459564 0.4060917  0.41124718 0.4142453         nan\n",
      "        nan 0.41411049 0.4083343  0.42022754 0.38350988        nan\n",
      "        nan        nan 0.40703955 0.4070215         nan 0.35619394\n",
      " 0.40283598        nan 0.42055322 0.41415869 0.40762539 0.3724923\n",
      " 0.41331068 0.4201663  0.39759133 0.41598395 0.40710749 0.42080983\n",
      "        nan 0.41068413 0.41426021        nan 0.41530447        nan\n",
      " 0.40225935 0.41282867 0.41161089 0.33108374 0.41197322 0.41415869\n",
      "        nan        nan 0.41502645 0.40058747 0.34006792 0.40172734\n",
      " 0.40344576 0.39572756        nan 0.40867302 0.41015986 0.39371607\n",
      " 0.40491113 0.41469083 0.3893259  0.35555811        nan 0.39176624\n",
      "        nan 0.41587781        nan        nan        nan        nan\n",
      " 0.40698688 0.35925293 0.39703655 0.41239483 0.41862272 0.41739207\n",
      " 0.39579574        nan 0.41606185 0.41146133 0.41307074        nan\n",
      " 0.40664126        nan 0.41731825 0.4146939  0.40855902 0.39224891\n",
      " 0.40074405        nan        nan 0.41279324 0.40602314 0.41545766\n",
      " 0.40737979        nan 0.34149852 0.41846207 0.40517135 0.40131037\n",
      " 0.401021   0.3398482  0.40269342 0.40747931 0.40946677 0.33546008\n",
      "        nan 0.41472872 0.41851252        nan 0.3910072         nan\n",
      " 0.41376926 0.41997609 0.40580769 0.39175886 0.33369726 0.40580769\n",
      "        nan 0.41298113 0.4150551  0.40842958        nan 0.41393897\n",
      " 0.41250308        nan 0.38241222 0.41150174 0.41473898        nan\n",
      " 0.411185   0.41422923 0.4128382         nan 0.40791089 0.4079383\n",
      "        nan 0.40479358 0.39231636 0.40195494 0.39184366 0.38910838\n",
      "        nan 0.40588888 0.41718682 0.40781095 0.41373196 0.41069106\n",
      "        nan 0.3417967  0.40586368 0.40252924        nan 0.42006053\n",
      " 0.41754009 0.41724268 0.38619267 0.41211707 0.40902419 0.39626339\n",
      " 0.40152849 0.34385237 0.40822403 0.38233101        nan        nan\n",
      " 0.41657193 0.34157279        nan 0.38673374 0.40297513        nan\n",
      " 0.41948136 0.41526177        nan 0.40182163 0.41615036 0.41893743\n",
      "        nan 0.40803685 0.41512968 0.41655089 0.41654575 0.40237943\n",
      " 0.41274493 0.40472915 0.40762572        nan 0.40476131        nan\n",
      "        nan 0.40678256 0.40224798 0.4158132  0.40154561        nan\n",
      "        nan        nan 0.4089996  0.39482652        nan 0.40170423\n",
      " 0.33374247 0.41561759 0.41296275 0.38496633 0.39463218 0.41605634\n",
      " 0.41145868 0.41476312        nan        nan 0.41856724 0.3849764\n",
      " 0.40902419 0.39425901 0.4070929  0.41800325 0.41240724        nan\n",
      " 0.41800325 0.40606263 0.40606892        nan 0.40709419 0.40248979\n",
      " 0.41722651        nan 0.41152133        nan        nan 0.41284823\n",
      "        nan        nan 0.40455052        nan        nan        nan\n",
      " 0.41432651 0.41194215 0.41723682 0.4079018  0.40927174 0.39308257\n",
      " 0.41645856 0.4182973  0.40592674 0.40271465 0.41223659 0.35426076\n",
      "        nan 0.41293447 0.39127199 0.41291874 0.40616334 0.4051716\n",
      " 0.41367592 0.4102     0.37254507 0.39382157        nan 0.38722286\n",
      " 0.41237905 0.41500827        nan 0.40904097 0.41705138 0.41479369\n",
      "        nan        nan 0.40921558        nan        nan 0.41270943\n",
      " 0.4038679  0.40818875 0.41293423 0.35258996 0.41763872 0.41520714\n",
      " 0.40584735        nan 0.39472968 0.40663931 0.41313204 0.39619094\n",
      " 0.39332649 0.41681327 0.41509323 0.41307054 0.40787638        nan\n",
      " 0.41249865 0.39866272 0.40358557 0.35189146 0.41483726 0.41266452\n",
      " 0.40990558 0.41946733 0.41986608 0.35925293 0.40767095        nan\n",
      "        nan 0.41857096 0.40203083 0.40109184 0.41293423 0.40056812\n",
      " 0.42074871 0.41434782 0.40266185 0.4163658  0.38456684 0.41634238\n",
      "        nan 0.40744523        nan        nan 0.40685489 0.39560836\n",
      " 0.36115164 0.41349699        nan 0.41878312 0.40916235 0.40276066\n",
      " 0.35943345 0.40509674 0.39233495        nan        nan 0.37601253\n",
      " 0.41725898 0.37240119        nan 0.39688112 0.41749533 0.4084634\n",
      " 0.4018784  0.40825457        nan        nan 0.41970435 0.40698424\n",
      "        nan 0.37356657 0.40540033        nan 0.39867818 0.39393774\n",
      " 0.37372914        nan 0.41732443 0.41123446        nan 0.41489526\n",
      "        nan 0.40493427 0.41530447 0.40791086 0.39643841 0.40238744\n",
      " 0.41658125        nan 0.41217302 0.35593172 0.41061382        nan\n",
      " 0.41934006 0.35929756]\n",
      "  warnings.warn(\n",
      "d:\\OneDrive\\Dokumenti\\ITU\\III.semester\\DAMIN\\Assignments Git Repository\\datamining-2\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:861: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__warm_start': True, 'classifier__oob_score': True, 'classifier__n_estimators': 500, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 2, 'classifier__max_features': 0.75, 'classifier__max_depth': 10, 'classifier__criterion': 'gini', 'classifier__class_weight': 'balanced', 'classifier__bootstrap': True}\n",
      "Best Score: 0.4208098285043852\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.78      0.64      1591\n",
      "           1       0.49      0.31      0.38      1650\n",
      "           2       0.22      0.31      0.26       678\n",
      "           3       0.38      0.29      0.33       910\n",
      "           4       0.58      0.49      0.53       789\n",
      "\n",
      "    accuracy                           0.46      5618\n",
      "   macro avg       0.44      0.44      0.43      5618\n",
      "weighted avg       0.47      0.46      0.45      5618\n",
      "\n",
      "Feature Importances:\n",
      "                  Feature  Importance\n",
      "8           depression_0    0.265848\n",
      "9           depression_1    0.086406\n",
      "12          depression_4    0.066177\n",
      "15             age_cat_2    0.049923\n",
      "10          depression_2    0.037548\n",
      "11          depression_3    0.026227\n",
      "0                 gender    0.023364\n",
      "16  medical_bill_worry_0    0.017524\n",
      "43                race_0    0.015118\n",
      "29           education_1    0.014878\n",
      "27            life_sat_3    0.014815\n",
      "7                 asthma    0.014695\n",
      "1                 single    0.014641\n",
      "22       health_status_3    0.014547\n",
      "18  medical_bill_worry_2    0.013707\n",
      "2              owns_home    0.013656\n",
      "3                 parent    0.013400\n",
      "5           hypertension    0.013399\n",
      "6            cholesterol    0.013344\n",
      "13             age_cat_0    0.012724\n",
      "35         poverty_cat_2    0.012442\n",
      "37         living_area_1    0.011710\n",
      "41             bmi_cat_1    0.011702\n",
      "23       health_status_4    0.011581\n",
      "34         poverty_cat_1    0.011559\n",
      "38         living_area_2    0.011396\n",
      "26            life_sat_2    0.011273\n",
      "30           education_2    0.011135\n",
      "20       health_status_1    0.011093\n",
      "42             bmi_cat_2    0.011060\n",
      "40             bmi_cat_0    0.010995\n",
      "39         living_area_3    0.010624\n",
      "17  medical_bill_worry_1    0.010496\n",
      "36         living_area_0    0.010393\n",
      "21       health_status_2    0.010291\n",
      "31           education_3    0.009952\n",
      "33         poverty_cat_0    0.009796\n",
      "28           education_0    0.009783\n",
      "14             age_cat_1    0.009412\n",
      "44                race_1    0.008027\n",
      "4                 cancer    0.007935\n",
      "25            life_sat_1    0.007925\n",
      "45                race_2    0.006911\n",
      "32           education_4    0.006603\n",
      "19       health_status_0    0.005353\n",
      "47                race_4    0.002671\n",
      "48                race_5    0.002561\n",
      "46                race_3    0.002540\n",
      "24            life_sat_0    0.000844\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.82      0.69      6363\n",
      "           1       0.62      0.38      0.47      6600\n",
      "           2       0.36      0.53      0.43      2713\n",
      "           3       0.56      0.44      0.50      3641\n",
      "           4       0.68      0.57      0.62      3153\n",
      "\n",
      "    accuracy                           0.56     22470\n",
      "   macro avg       0.56      0.55      0.54     22470\n",
      "weighted avg       0.58      0.56      0.55     22470\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' model.fit(X_resampled, y_resampled)\\ny_pred = model.predict(X_test)\\nprint(classification_report(y_true=y_test, y_pred=y_pred)) '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop([\"anxiety\"], axis=1)\n",
    "y = df[\"anxiety\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_distributions = {\n",
    "    'classifier__n_estimators': [50, 150, 300, 500],  \n",
    "    'classifier__max_depth': [None, 10, 20, 50],\n",
    "    'classifier__min_samples_split': [2, 5, 10, 20],    \n",
    "    'classifier__min_samples_leaf': [1, 2, 5, 10, 20],  \n",
    "    'classifier__max_features': ['sqrt', 'log2', None, 0.5, 0.75],  \n",
    "    'classifier__bootstrap': [True, False],             \n",
    "    'classifier__criterion': ['gini', 'entropy'],       \n",
    "    'classifier__class_weight': [None, 'balanced', 'balanced_subsample'],  \n",
    "    'classifier__oob_score': [True, False],             \n",
    "    'classifier__warm_start': [True, False]        \n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=500,           # Number of random samples\n",
    "    scoring='f1_macro',  \n",
    "    cv=5,    \n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", search.best_params_)\n",
    "print(\"Best Score:\", search.best_score_)\n",
    "\n",
    "best_model = search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Analyze feature importances\n",
    "feature_importances = best_model.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Pair each feature importance with the feature name\n",
    "feature_names = X.columns\n",
    "feature_importances_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "print(\"Feature Importances:\\n\", feature_importances_df.sort_values(by='Importance', ascending=False))\n",
    "\n",
    "# Calculate metrics on the training data to check for overfitting\n",
    "train_pred = best_model.predict(X_train)\n",
    "train_report = classification_report(y_train, train_pred)\n",
    "print(\"Training Classification Report:\\n\", train_report)\n",
    "\n",
    "\n",
    "\"\"\" smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train) \"\"\"\n",
    "\n",
    "\"\"\" model = RandomForestClassifier(\n",
    "    bootstrap=False,\n",
    "    random_state=42,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=None,\n",
    "    max_features=\"sqrt\",\n",
    "    min_samples_split=2,\n",
    "    n_estimators=500\n",
    ") \"\"\"\n",
    "\n",
    "# model = KNeighborsClassifier(n_neighbors=11 )\n",
    "\n",
    "\"\"\" model = MLPClassifier(\n",
    "    hidden_layer_sizes=(10, 8),  # Two hidden layers with 5 and 4 neurons\n",
    "    activation='relu',           # Activation function for hidden layers\n",
    "    solver='adam',               # Optimizer\n",
    "    max_iter=250,                # Maximum iterations\n",
    "    random_state=42,              # For reproducibility\n",
    "    alpha = 0.0001,\n",
    "    batch_size = 64,\n",
    "    learning_rate='adaptive',\n",
    "    learning_rate_init=0.001  \n",
    ") \"\"\"\n",
    "\n",
    "#model = SVC(kernel=\"rbf\", C=1, gamma=\"scale\", decision_function_shape=\"ovr\")\n",
    "\n",
    "\"\"\" model = XGBClassifier(\n",
    "    random_state = 42,\n",
    "    learning_rate=0.2\n",
    ") \"\"\"\n",
    "\n",
    "\"\"\" model = HistGradientBoostingClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=3, \n",
    "    max_iter=400\n",
    ") \"\"\"\n",
    "\n",
    "\"\"\" model.fit(X_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred)) \"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
