{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Project II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from enum import IntEnum\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error, mean_absolute_error, mean_squared_error, accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR 2022\n",
      "features: 637\n",
      "entries: 27651\n",
      "YEAR 2023\n",
      "features: 647\n",
      "entries: 29522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['weight',\n",
       " 'height',\n",
       " 'pregnant',\n",
       " 'age',\n",
       " 'gender',\n",
       " 'education',\n",
       " 'single',\n",
       " 'owns_home',\n",
       " 'parent',\n",
       " 'depression',\n",
       " 'anxiety',\n",
       " 'poverty',\n",
       " 'health_status',\n",
       " 'life_sat',\n",
       " 'insurance',\n",
       " 'living_area',\n",
       " 'region',\n",
       " 'cancer',\n",
       " 'hypertension',\n",
       " 'cholesterol',\n",
       " 'asthma',\n",
       " 'race',\n",
       " 'medical_bill_worry']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = {\n",
    "    \"WEIGHTLBTC_A\": \"weight\", #pounds\n",
    "    \"HEIGHTTC_A\": \"height\", #inches\n",
    "    \"PREGNOW_A\": \"pregnant\",\n",
    "    \"AGEP_A\": \"age\",\n",
    "    \"SEX_A\": \"gender\",\n",
    "    \"EDUCP_A\": \"education\",\n",
    "    \"MARITAL_A\": \"single\",\n",
    "    \"HOUTENURE_A\": \"owns_home\",\n",
    "    \"PARSTAT_A\": \"parent\",\n",
    "    \"DEPFREQ_A\": \"depression\",\n",
    "    \"ANXFREQ_A\": \"anxiety\",\n",
    "    \"POVRATTC_A\": \"poverty\",\n",
    "    \"PHSTAT_A\": \"health_status\",\n",
    "    \"LSATIS4_A\": \"life_sat\",\n",
    "    #\"DRK12MN_A\": \"alcohol\",\n",
    "    #\"SLPHOURS_A\": \"sleep\",\n",
    "    \"NOTCOV_A\": \"insurance\",\n",
    "    \"URBRRL\": \"living_area\",\n",
    "    \"REGION\": \"region\",\n",
    "    \"CANEV_A\": \"cancer\",\n",
    "    \"HYPEV_A\": \"hypertension\",\n",
    "    \"CHLEV_A\": \"cholesterol\",\n",
    "    \"ASEV_A\": \"asthma\",\n",
    "    \"RACEALLP_A\": \"race\",\n",
    "    \"PAYWORRY_A\": \"medical_bill_worry\"\n",
    "}\n",
    "\n",
    "dataframes = []\n",
    "for i in [2, 3]:\n",
    "    df = pd.read_csv(f\"../data/adult2{i}.csv\", sep=\",\")\n",
    "    dataframes.append(df)\n",
    "    print(f\"YEAR 202{i}\\nfeatures: {len(df.columns)}\\nentries: {len(df)}\")\n",
    "    for attr in attributes.keys():\n",
    "        try:\n",
    "            (f\"{attr}: {df[attr].unique()[:(min(10, len(df[attr].unique())))]}\")\n",
    "        except:\n",
    "            print(f\"missing {attr} for 202{i}\")\n",
    "df = pd.concat(dataframes)\n",
    "df = df.loc[:, list(attributes.keys())]\n",
    "df.rename(mapper=attributes, inplace=True, axis=1)\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>single</th>\n",
       "      <th>owns_home</th>\n",
       "      <th>parent</th>\n",
       "      <th>depression</th>\n",
       "      <th>...</th>\n",
       "      <th>life_sat</th>\n",
       "      <th>insurance</th>\n",
       "      <th>living_area</th>\n",
       "      <th>region</th>\n",
       "      <th>cancer</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>asthma</th>\n",
       "      <th>race</th>\n",
       "      <th>medical_bill_worry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>235</td>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>218</td>\n",
       "      <td>69</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29517</th>\n",
       "      <td>190</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29518</th>\n",
       "      <td>165</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29519</th>\n",
       "      <td>220</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29520</th>\n",
       "      <td>170</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29521</th>\n",
       "      <td>155</td>\n",
       "      <td>67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57173 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       weight  height  pregnant  age  gender  education  single  owns_home  \\\n",
       "0         148      68       NaN   85       1          4       3          1   \n",
       "1         235      74       NaN   64       1          8       1          1   \n",
       "2         218      69       2.0   37       2          8       1          1   \n",
       "3         240      64       NaN   72       2          5       2          1   \n",
       "4         183      66       NaN   84       2          6       3          1   \n",
       "...       ...     ...       ...  ...     ...        ...     ...        ...   \n",
       "29517     190      61       NaN   77       2          5       3          1   \n",
       "29518     165      65       NaN   59       2          7       1          1   \n",
       "29519     220      66       NaN   66       1          8       1          1   \n",
       "29520     170      65       NaN   53       2          7       1          1   \n",
       "29521     155      67       NaN   72       2          8       1          1   \n",
       "\n",
       "       parent  depression  ...  life_sat  insurance  living_area  region  \\\n",
       "0           3           5  ...         2          2            2       3   \n",
       "1           3           5  ...         2          2            4       3   \n",
       "2           3           4  ...         1          2            4       3   \n",
       "3           3           5  ...         1          2            4       3   \n",
       "4           3           5  ...         2          2            1       3   \n",
       "...       ...         ...  ...       ...        ...          ...     ...   \n",
       "29517       3           3  ...         2          2            4       4   \n",
       "29518       3           4  ...         1          2            4       4   \n",
       "29519       3           4  ...         2          2            4       4   \n",
       "29520       3           5  ...         1          2            4       4   \n",
       "29521       3           5  ...         1          2            4       4   \n",
       "\n",
       "       cancer  hypertension  cholesterol  asthma  race  medical_bill_worry  \n",
       "0           2             1            2       2     1                   3  \n",
       "1           1             1            1       2     1                   3  \n",
       "2           2             2            2       1     1                   3  \n",
       "3           2             1            2       1     1                   3  \n",
       "4           2             1            2       2     2                   2  \n",
       "...       ...           ...          ...     ...   ...                 ...  \n",
       "29517       2             1            1       1     1                   2  \n",
       "29518       2             2            1       2     1                   3  \n",
       "29519       2             2            2       1     1                   2  \n",
       "29520       2             1            2       1     1                   3  \n",
       "29521       2             1            1       1     1                   3  \n",
       "\n",
       "[57173 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"weight\"] <= 299]\n",
    "df = df[df[\"height\"] <= 76]\n",
    "df = df[((df[\"pregnant\"] == 2) | (df[\"gender\"] == 1))]\n",
    "df = df[df[\"age\"] <= 84]\n",
    "df = df[df[\"gender\"] <= 2]\n",
    "df = df[df[\"education\"] <= 10]\n",
    "df = df[df[\"single\"] <= 3]\n",
    "df = df[df[\"owns_home\"] <= 3]\n",
    "df = df[df[\"parent\"] <= 3]\n",
    "df = df[df[\"depression\"] <= 5]\n",
    "df = df[df[\"anxiety\"] <= 5]\n",
    "df = df[df[\"poverty\"] < 11]\n",
    "df = df[df[\"health_status\"] < 6]\n",
    "df = df[df[\"life_sat\"] < 5]\n",
    "#df = df[df[\"alcohol\"] < 366]\n",
    "#df = df[df[\"sleep\"] < 25]\n",
    "df = df[df[\"insurance\"] <= 2]\n",
    "# living area is good as it is\n",
    "# region too\n",
    "df = df[df[\"cancer\"] <= 2]\n",
    "df = df[df[\"hypertension\"] <= 2]\n",
    "df = df[df[\"cholesterol\"] <= 2]\n",
    "df = df[df[\"asthma\"] <= 2]\n",
    "df = df[df[\"race\"] <= 6]\n",
    "df = df[df[\"medical_bill_worry\"] <= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI calculation\n",
    "POUND_TO_KG = 0.453592\n",
    "INCH_TO_M = 0.0254\n",
    "df[\"weight\"] = df[\"weight\"] * POUND_TO_KG\n",
    "df[\"height\"] = df[\"height\"] * INCH_TO_M\n",
    "df[\"bmi\"] = df[\"weight\"] / df[\"height\"] ** 2\n",
    "\n",
    "del df[\"weight\"]\n",
    "del df[\"height\"]\n",
    "del df[\"pregnant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_cluster_number(df: pd.DataFrame, feature: str, k_number: int) -> int:\n",
    "    inertia = []\n",
    "    k_values = np.arange(1, k_number+1)\n",
    "\n",
    "    for k in k_values:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(df[[feature]])\n",
    "        inertia.append(kmeans.inertia_)\n",
    "\n",
    "    knee_locator = KneeLocator(k_values, inertia, curve='convex', direction='decreasing')\n",
    "    k = knee_locator.knee\n",
    "\n",
    "\n",
    "    \"\"\"fig, ax = plt.subplots(1, figsize=(8, 6))\n",
    "    ax.plot(k_values, inertia, marker='o')\n",
    "    ax.set(xlabel='Number of clusters (k)', ylabel='Inertia', title=f'Elbow Method for Optimal k for {feature}')\n",
    "    ax.axvline(x=elbow_point, c=\"red\")\n",
    "    ax.set_xticks(k_values) \"\"\"\n",
    "\n",
    "    return k, k_values, inertia\n",
    "\n",
    "def plot_cluster(df: pd.DataFrame, feature:str, k_values: np.ndarray, inertia: np.ndarray, k: int):\n",
    "    fig, axs = plt.subplots(2, figsize=(8, 6))\n",
    "    axs[0].plot(k_values, inertia, marker='o')\n",
    "    axs[0].set(xlabel='Number of clusters (k)', ylabel='Inertia', title=f'Elbow Method for Optimal k for {feature}')\n",
    "    axs[0].axvline(x=k, c=\"red\")\n",
    "    axs[0].set_xticks(k_values)\n",
    "\n",
    "    axs[1].scatter(df[feature], df[f'{feature}_cat'], c=df[f'{feature}_cat'], cmap='viridis')\n",
    "    axs[1].set_title(f\"{feature} Categories using K-Means Clustering\")\n",
    "    axs[1].set_xlabel(feature)\n",
    "    axs[1].set_ylabel(\"Category\")\n",
    "\n",
    "    \n",
    "CONTINUOUS_FEATURES = [\"age\", \"bmi\", \"poverty\"]\n",
    "for feature in CONTINUOUS_FEATURES:\n",
    "    k, k_values, inertia = get_optimal_cluster_number(df, feature, 10)\n",
    "    kmeans = KMeans(n_clusters=k, n_init=5, random_state=42)\n",
    "    df[f\"{feature}_cat\"] = kmeans.fit_predict(df[[feature]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regrouping\n",
    "\n",
    "\"\"\"\n",
    "EDUCATION\n",
    "00 (no edu), 01 (no hs), 02 (no diploma): no_hs\n",
    "03 (ged), 04 (hs), 05 (no deg): highschool\n",
    "06 (occupational deg), 07 (academic deg), 08 (bsc): bachelor\n",
    "09 (msc): masters\n",
    "10 (phd): phd\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "MARITAL status:\n",
    "03: single\n",
    "01 (married) 2 (cohabiting): not\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "parent\n",
    "01: parent\n",
    "02 (in famility but not) 03 (not in family): not\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def invert_encoding_order(df: pd.DataFrame, feature: str) -> None:\n",
    "    \"\"\"Reorders the encoding of a categorical variable, \n",
    "    so that the lowest values are encoded 0 and higher ones ascending from here.\"\"\"\n",
    "    df[feature] = df[feature].max() - df[feature]\n",
    "\n",
    "def offset_encoding_to_zero(df: pd.DataFrame, feature: str) -> None:\n",
    "    \"\"\"Re-encodes `1` and `2` category labels into `0` and `1`\"\"\"\n",
    "    df[feature] = df[feature] - 1\n",
    "\n",
    "\n",
    "offset_encoding_to_zero(df, \"gender\") \n",
    "\n",
    "class EduLevel(IntEnum):\n",
    "    NO_HIGHSCHOOL = 0\n",
    "    HIGHSCHOOL = 1\n",
    "    BACHELORS = 2\n",
    "    MASTERS = 3\n",
    "    PHD = 4\n",
    "    \n",
    "df[\"education\"] = df[\"education\"].replace({\n",
    "    1: EduLevel.NO_HIGHSCHOOL,\n",
    "    2: EduLevel.NO_HIGHSCHOOL,\n",
    "    3: EduLevel.HIGHSCHOOL,\n",
    "    4: EduLevel.HIGHSCHOOL,\n",
    "    5: EduLevel.HIGHSCHOOL,\n",
    "    6: EduLevel.BACHELORS,\n",
    "    7: EduLevel.BACHELORS,\n",
    "    8: EduLevel.BACHELORS,\n",
    "    9: EduLevel.MASTERS,\n",
    "    10: EduLevel.PHD\n",
    "})\n",
    "\n",
    "df[\"single\"] = df[\"single\"].replace({\n",
    "    1: 0,\n",
    "    2: 0,\n",
    "    3: 1\n",
    "})\n",
    "\n",
    "df[\"owns_home\"] = df[\"owns_home\"].replace({\n",
    "    1: 1,\n",
    "    2: 0,\n",
    "    3: 0,\n",
    "})\n",
    "\n",
    "df[\"parent\"] = df[\"parent\"].replace({\n",
    "    1: 1,\n",
    "    2: 0,\n",
    "    3: 0\n",
    "})\n",
    "\n",
    "\n",
    "invert_encoding_order(df, \"depression\")\n",
    "\n",
    "invert_encoding_order(df, \"anxiety\")\n",
    "\n",
    "invert_encoding_order(df, \"health_status\")\n",
    "\n",
    "invert_encoding_order(df, \"life_sat\")\n",
    "\n",
    "offset_encoding_to_zero(df, \"insurance\") \n",
    "\n",
    "invert_encoding_order(df, \"living_area\")\n",
    "\n",
    "offset_encoding_to_zero(df, \"region\") \n",
    "\n",
    "invert_encoding_order(df, \"cancer\")\n",
    "\n",
    "invert_encoding_order(df, \"hypertension\")\n",
    "\n",
    "invert_encoding_order(df, \"cholesterol\")\n",
    "\n",
    "invert_encoding_order(df, \"asthma\")\n",
    "\n",
    "offset_encoding_to_zero(df, \"race\") \n",
    "\n",
    "invert_encoding_order(df, \"medical_bill_worry\")\n",
    "\n",
    "df[\"age_cat\"] = df[\"age_cat\"].replace({\n",
    "    1: 0,\n",
    "    2: 1,\n",
    "    0: 2,\n",
    "})\n",
    "\n",
    "df[\"bmi_cat\"] = df[\"bmi_cat\"].replace({\n",
    "    2: 0,\n",
    "    0: 1,\n",
    "    1: 2,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(CONTINUOUS_FEATURES, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crosstables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' target = \"anxiety\"\\n\\nfor f in df.columns.values:\\n    tab = pd.crosstab(df[f], df[target], normalize=\"index\") * 100\\n    plt.figure(figsize=(6, 3))\\n    sns.heatmap(tab, fmt=\\'.2f\\', cmap=\\'coolwarm\\', annot=True)\\n    plt.show() '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" target = \"anxiety\"\n",
    "\n",
    "for f in df.columns.values:\n",
    "    tab = pd.crosstab(df[f], df[target], normalize=\"index\") * 100\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    sns.heatmap(tab, fmt='.2f', cmap='coolwarm', annot=True)\n",
    "    plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-square tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               feature           chi              p  cramers_v\n",
      "0           depression  15793.186491   0.000000e+00   0.365245\n",
      "1              age_cat   1425.727603  1.823056e-307   0.203438\n",
      "2   medical_bill_worry   1251.239725  1.240938e-269   0.176973\n",
      "3               gender   1104.225585  9.189134e-238   0.241981\n",
      "4        health_status    361.803253   4.957452e-77   0.107268\n",
      "5               asthma    360.400786   9.956869e-77   0.122311\n",
      "6             life_sat    345.419779   1.709514e-73   0.181856\n",
      "7            education    198.090764   9.667944e-42   0.065800\n",
      "8         hypertension    178.677826   1.433765e-37   0.095869\n",
      "9            owns_home    155.439801   1.389187e-32   0.124100\n",
      "10         poverty_cat    136.038180   1.989087e-28   0.071849\n",
      "11              single    119.390361   7.208863e-25   0.087790\n",
      "12         cholesterol    107.485402   2.501311e-22   0.072131\n",
      "13              parent     99.974694   9.959406e-21   0.071301\n",
      "14              cancer     98.369083   2.187737e-20   0.062055\n",
      "15         living_area     66.011423   1.575264e-13   0.037626\n",
      "16             bmi_cat     62.934506   7.004726e-13   0.050456\n",
      "17                race     39.362905   5.861853e-08   0.051657\n",
      "18           insurance      1.305928   8.603690e-01   0.023574\n",
      "19              region      0.927628   9.205641e-01   0.028454\n"
     ]
    }
   ],
   "source": [
    "X = df.drop([\"anxiety\"], axis=1)\n",
    "y = df['anxiety']\n",
    "\n",
    "#chi2_scores, p_values = chi2(X, y)\n",
    "\n",
    "\n",
    "#Calculate Cramér's V for two categorical variables\n",
    "def cramers_v(x, y):    \n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    return np.sqrt(phi2 / min(r - 1, k - 1))\n",
    "\n",
    "feature_names = X.columns\n",
    "chi2_scores = []\n",
    "p_values = []\n",
    "cramers_v_values = []\n",
    "\n",
    "# Calculate Chi-Square, p-value, and Cramér's V for each feature\n",
    "for feature in feature_names:\n",
    "    chi2_score, p_value = chi2(X[[feature]], y)\n",
    "    chi2_scores.append(chi2_score[0])  # chi2() returns an array\n",
    "    p_values.append(p_value[0])       # chi2() returns an array\n",
    "    v = cramers_v(X[feature], y)\n",
    "    cramers_v_values.append(v)\n",
    "\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'chi': chi2_scores,\n",
    "    'p': p_values,\n",
    "    'cramers_v': cramers_v_values\n",
    "}).sort_values(by='p', ignore_index=True)\n",
    "\n",
    "print(results)\n",
    "\n",
    "alpha = 0.05\n",
    "cramers = 0.1\n",
    "significant_features = results[(results[\"p\"] < alpha) & (results[\"cramers_v\"] > cramers)][\"feature\"].values\n",
    "insignificant_features =  results[(results[\"p\"] >= alpha) | (results[\"cramers_v\"] <= cramers)][\"feature\"].values\n",
    "\n",
    "df.drop(insignificant_features, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>owns_home</th>\n",
       "      <th>depression</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>health_status</th>\n",
       "      <th>life_sat</th>\n",
       "      <th>asthma</th>\n",
       "      <th>medical_bill_worry</th>\n",
       "      <th>age_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29513</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29514</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29515</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29516</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29519</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28088 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender  owns_home  depression  anxiety  health_status  life_sat  \\\n",
       "1           0          1           0        1              2         2   \n",
       "2           1          1           1        2              2         3   \n",
       "10          0          1           1        1              2         2   \n",
       "11          0          1           0        0              4         3   \n",
       "15          1          0           4        4              2         1   \n",
       "...       ...        ...         ...      ...            ...       ...   \n",
       "29513       1          0           2        3              2         2   \n",
       "29514       1          1           1        2              4         3   \n",
       "29515       0          1           0        2              3         3   \n",
       "29516       1          1           0        3              2         3   \n",
       "29519       0          1           1        3              2         2   \n",
       "\n",
       "       asthma  medical_bill_worry  age_cat  \n",
       "1           0                   0        2  \n",
       "2           1                   0        1  \n",
       "10          0                   0        2  \n",
       "11          0                   0        2  \n",
       "15          0                   1        0  \n",
       "...       ...                 ...      ...  \n",
       "29513       1                   1        0  \n",
       "29514       0                   1        0  \n",
       "29515       0                   0        1  \n",
       "29516       0                   2        1  \n",
       "29519       1                   1        2  \n",
       "\n",
       "[28088 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_columns = [column for column in significant_features if len(df[column].unique()) > 2] \n",
    "df = pd.get_dummies(df, columns=one_hot_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive\\Dokumenti\\ITU\\III.semester\\DAMIN\\Assignments Git Repository\\datamining-2\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "610 fits failed out of a total of 2500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "610 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\OneDrive\\Dokumenti\\ITU\\III.semester\\DAMIN\\Assignments Git Repository\\datamining-2\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\OneDrive\\Dokumenti\\ITU\\III.semester\\DAMIN\\Assignments Git Repository\\datamining-2\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\OneDrive\\Dokumenti\\ITU\\III.semester\\DAMIN\\Assignments Git Repository\\datamining-2\\.venv\\Lib\\site-packages\\imblearn\\pipeline.py\", line 333, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n",
      "  File \"d:\\OneDrive\\Dokumenti\\ITU\\III.semester\\DAMIN\\Assignments Git Repository\\datamining-2\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\OneDrive\\Dokumenti\\ITU\\III.semester\\DAMIN\\Assignments Git Repository\\datamining-2\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\OneDrive\\Dokumenti\\ITU\\III.semester\\DAMIN\\Assignments Git Repository\\datamining-2\\.venv\\Lib\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "d:\\OneDrive\\Dokumenti\\ITU\\III.semester\\DAMIN\\Assignments Git Repository\\datamining-2\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.394767   0.403003   0.40657436        nan 0.39109675 0.39477705\n",
      " 0.39737368 0.398173          nan 0.38496437        nan 0.3941361\n",
      " 0.40014125 0.39348791 0.39178506 0.39905104        nan 0.40214774\n",
      "        nan        nan        nan 0.39607467 0.4029645  0.40844213\n",
      " 0.39722569 0.40307036 0.39993258 0.40448318        nan 0.40118711\n",
      "        nan        nan 0.397235          nan        nan        nan\n",
      " 0.39830735 0.40334835 0.40455416 0.40516689 0.40235075 0.39150749\n",
      " 0.39499057 0.39867933        nan 0.39737918 0.39314275 0.38852824\n",
      " 0.40163021        nan 0.39361296        nan 0.40189311 0.39600608\n",
      " 0.40285594 0.38996276 0.38732011        nan        nan        nan\n",
      " 0.39751785 0.39433276        nan 0.39177216 0.39168937 0.39794236\n",
      "        nan 0.39078933 0.40390004 0.39629169        nan 0.39458639\n",
      " 0.3941361         nan 0.40409041 0.39433089        nan        nan\n",
      "        nan        nan 0.40458606 0.39870165        nan 0.39558554\n",
      " 0.40348156 0.40297261 0.39346665        nan 0.38758144 0.4084281\n",
      " 0.39377668 0.39735722 0.39658258        nan 0.39855823 0.39368123\n",
      "        nan 0.39535816 0.39928262 0.40826509        nan        nan\n",
      "        nan 0.39813815 0.39817292 0.3956034  0.39277055        nan\n",
      " 0.40076344        nan 0.40430489 0.39296989 0.40708196 0.39669995\n",
      " 0.40341534 0.39454107 0.39683311 0.3946709  0.40396379 0.39634844\n",
      "        nan 0.3979978  0.40556622        nan 0.39359003 0.39936646\n",
      " 0.3988168         nan        nan 0.3946752  0.38012194 0.39823561\n",
      " 0.40435145 0.39331819        nan 0.40307681 0.39702702 0.40858684\n",
      " 0.39920043        nan        nan 0.39996115 0.39964834 0.4041391\n",
      " 0.38523205 0.40594126        nan 0.39257501 0.40329416 0.38601526\n",
      " 0.39920043 0.38733374 0.39440465        nan        nan 0.39858227\n",
      " 0.38930291 0.40359065 0.38877468 0.40438439        nan 0.40262005\n",
      "        nan 0.39421509        nan 0.39443922 0.39858445 0.39890861\n",
      " 0.39050117 0.38898303 0.39733636        nan 0.39628861 0.39867908\n",
      " 0.40408771        nan 0.39461649 0.39254254 0.4028361  0.3984033\n",
      " 0.39621366        nan 0.39656597 0.39641138 0.40019668 0.39173256\n",
      "        nan 0.39448269 0.40425569 0.39122164 0.39902633        nan\n",
      " 0.39641138 0.40358209 0.39430986        nan        nan 0.39776902\n",
      " 0.39658258        nan 0.39793173 0.40860929        nan 0.40203244\n",
      " 0.40336218 0.39894053 0.39587912 0.3998641         nan 0.39557779\n",
      " 0.40477358 0.40112652        nan 0.39271388        nan        nan\n",
      " 0.40312772 0.40085497 0.38688048        nan 0.39988871        nan\n",
      " 0.3947582  0.39598088 0.39270149 0.3892862  0.40115448 0.39351952\n",
      " 0.39220031 0.39634844 0.40102132 0.40317235 0.39363592 0.40259688\n",
      "        nan 0.39503568 0.40400206 0.40081581 0.40090878 0.40445508\n",
      "        nan 0.40532161 0.39367348        nan 0.40602015 0.39901042\n",
      " 0.3998949  0.40256293        nan 0.3834048  0.40495504 0.4001515\n",
      " 0.38908591 0.40534129        nan 0.39312291 0.40326686 0.39687082\n",
      " 0.40261793        nan 0.40826509 0.40219029 0.40740049        nan\n",
      " 0.39558791 0.40053999        nan 0.39838216 0.39964834 0.38971805\n",
      "        nan 0.40111528 0.38689093        nan 0.39944954 0.38498095\n",
      " 0.38662697 0.39668449 0.39253863 0.39059444 0.39437773 0.40243257\n",
      " 0.39232177 0.40374289 0.39400645 0.38385604        nan        nan\n",
      " 0.39458639 0.4034861  0.40114858 0.38776783 0.40343348 0.39964834\n",
      " 0.38318761        nan 0.40090694 0.40933805        nan 0.40448318\n",
      "        nan 0.40364399        nan 0.39091577        nan 0.40633301\n",
      " 0.40069132        nan        nan 0.40965814 0.40348156 0.39390872\n",
      " 0.39568459 0.39921584 0.39601586 0.40893226 0.39634719 0.39308727\n",
      " 0.39623285        nan        nan 0.38952232 0.39040544 0.39070061\n",
      " 0.3819344  0.39998817 0.39916411 0.40526948 0.40452773 0.39746047\n",
      " 0.39914506 0.4036527         nan 0.40345624 0.40204097 0.39863042\n",
      " 0.40684479 0.39454107 0.39652524 0.40407014 0.40407014 0.3946752\n",
      "        nan 0.40335852 0.40295562 0.39620563 0.39703942 0.39430275\n",
      " 0.39159644 0.39719632 0.39967264        nan 0.39073677 0.39050117\n",
      " 0.40149819 0.39094097 0.39937385 0.39682189 0.39637673 0.39853375\n",
      " 0.3930519  0.39975992 0.39832478 0.3947582         nan        nan\n",
      " 0.39220031        nan 0.40662208 0.396118   0.40132062 0.40105074\n",
      " 0.40069138 0.39817292 0.4006904  0.39741313 0.40153242 0.39214487\n",
      " 0.3936175  0.39507774 0.4004134  0.39257501 0.39906601 0.4049963\n",
      "        nan 0.39786045 0.39470236        nan 0.39059444 0.39829658\n",
      " 0.39535816 0.40232814 0.39960727 0.3952721  0.40236288 0.38689093\n",
      " 0.39161426        nan 0.40367811 0.40426306 0.39493614 0.4020585\n",
      " 0.39818375 0.39546745        nan 0.38777546 0.40252998 0.40304606\n",
      " 0.39150942 0.39579804 0.40101224        nan 0.39853375        nan\n",
      "        nan 0.38637176 0.39646373        nan 0.38597293 0.3932534\n",
      " 0.4087679  0.39437773 0.38792179        nan 0.40333639 0.39289201\n",
      "        nan 0.39437773 0.39815749        nan 0.40448318 0.39925799\n",
      " 0.39368508        nan 0.39244629 0.40423672 0.39111441 0.38593793\n",
      " 0.39558581 0.40633301 0.39658258 0.40448318 0.4008986         nan\n",
      "        nan 0.40117821        nan 0.39111441 0.40657436 0.40528214\n",
      "        nan 0.39998817 0.39414633 0.40464785        nan        nan\n",
      " 0.4036725         nan 0.39838509 0.39887567 0.37816548 0.40520318\n",
      " 0.39419044        nan        nan 0.40359593        nan 0.3942125\n",
      "        nan 0.39851792        nan        nan        nan 0.40531057\n",
      " 0.40374289 0.40243466        nan 0.38101172 0.4041391  0.40657436\n",
      " 0.40079043 0.40374831 0.39538183 0.40209352 0.39917683 0.39505964\n",
      " 0.3950928         nan 0.39717235 0.3881002  0.39721174        nan\n",
      " 0.40325807 0.39411872 0.39598088        nan 0.39235997        nan\n",
      " 0.40128433 0.39418077]\n",
      "  warnings.warn(\n",
      "d:\\OneDrive\\Dokumenti\\ITU\\III.semester\\DAMIN\\Assignments Git Repository\\datamining-2\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:861: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__warm_start': True, 'classifier__oob_score': True, 'classifier__n_estimators': 50, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 20, 'classifier__max_features': None, 'classifier__max_depth': 50, 'classifier__criterion': 'gini', 'classifier__class_weight': 'balanced_subsample', 'classifier__bootstrap': True}\n",
      "Best Score: 0.40965814459252775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.77      0.63      1591\n",
      "           1       0.47      0.28      0.35      1650\n",
      "           2       0.20      0.28      0.24       678\n",
      "           3       0.34      0.26      0.30       910\n",
      "           4       0.54      0.51      0.52       789\n",
      "\n",
      "    accuracy                           0.45      5618\n",
      "   macro avg       0.42      0.42      0.41      5618\n",
      "weighted avg       0.45      0.45      0.43      5618\n",
      "\n",
      "Feature Importances:\n",
      "                  Feature  Importance\n",
      "3           depression_0    0.376707\n",
      "4           depression_1    0.160012\n",
      "10             age_cat_2    0.078321\n",
      "5           depression_2    0.069867\n",
      "1              owns_home    0.037197\n",
      "0                 gender    0.028359\n",
      "11  medical_bill_worry_0    0.026610\n",
      "17       health_status_3    0.024147\n",
      "7           depression_4    0.022856\n",
      "22            life_sat_3    0.020234\n",
      "16       health_status_2    0.019362\n",
      "2                 asthma    0.017680\n",
      "13  medical_bill_worry_2    0.015737\n",
      "12  medical_bill_worry_1    0.015694\n",
      "18       health_status_4    0.015645\n",
      "21            life_sat_2    0.015065\n",
      "8              age_cat_0    0.013987\n",
      "6           depression_3    0.013627\n",
      "15       health_status_1    0.011738\n",
      "9              age_cat_1    0.011582\n",
      "20            life_sat_1    0.002720\n",
      "14       health_status_0    0.002712\n",
      "19            life_sat_0    0.000143\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.78      0.64      6363\n",
      "           1       0.50      0.29      0.37      6600\n",
      "           2       0.26      0.38      0.31      2713\n",
      "           3       0.42      0.32      0.36      3641\n",
      "           4       0.58      0.52      0.55      3153\n",
      "\n",
      "    accuracy                           0.48     22470\n",
      "   macro avg       0.46      0.46      0.45     22470\n",
      "weighted avg       0.48      0.48      0.46     22470\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' model.fit(X_train, y_train)\\ny_pred = model.predict(X_test)\\nprint(classification_report(y_true=y_test, y_pred=y_pred))\\n\\n# For RandomForestClassifier\\nfeature_importances = model.feature_importances_\\n\\n# Pair each feature importance with the feature name\\nfeature_names = X.columns\\nfeature_importances_df = pd.DataFrame({\\'Feature\\': feature_names, \\'Importance\\': feature_importances})\\nprint(\"Feature Importances:\\n\", feature_importances_df.sort_values(by=\\'Importance\\', ascending=False, ignore_index=True))\\n\\n# Calculate metrics on the training data to check for overfitting\\ntrain_pred = model.predict(X_train)\\ntrain_report = classification_report(y_train, train_pred)\\nprint(\"Training Classification Report:\\n\", train_report)\\n '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop([\"anxiety\"], axis=1)\n",
    "y = df[\"anxiety\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_distributions = {\n",
    "    'classifier__n_estimators': [50, 150, 300, 500],  \n",
    "    'classifier__max_depth': [None, 10, 20, 50],\n",
    "    'classifier__min_samples_split': [2, 5, 10, 20],    \n",
    "    'classifier__min_samples_leaf': [1, 2, 5, 10, 20],  \n",
    "    'classifier__max_features': ['sqrt', 'log2', None, 0.5, 0.75],  \n",
    "    'classifier__bootstrap': [True, False],             \n",
    "    'classifier__criterion': ['gini', 'entropy'],       \n",
    "    'classifier__class_weight': [None, 'balanced', 'balanced_subsample'],  \n",
    "    'classifier__oob_score': [True, False],             \n",
    "    'classifier__warm_start': [True, False]        \n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=500,           # Number of random samples\n",
    "    scoring='f1_macro',  \n",
    "    cv=5,    \n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", search.best_params_)\n",
    "print(\"Best Score:\", search.best_score_)\n",
    "\n",
    "best_model = search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Analyze feature importances\n",
    "feature_importances = best_model.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Pair each feature importance with the feature name\n",
    "feature_names = X.columns\n",
    "feature_importances_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "print(\"Feature Importances:\\n\", feature_importances_df.sort_values(by='Importance', ascending=False))\n",
    "\n",
    "# Calculate metrics on the training data to check for overfitting\n",
    "train_pred = best_model.predict(X_train)\n",
    "train_report = classification_report(y_train, train_pred)\n",
    "print(\"Training Classification Report:\\n\", train_report)\n",
    "\n",
    "\n",
    "\"\"\" smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train) \"\"\"\n",
    "\n",
    "\"\"\" model = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    criterion=\"gini\",\n",
    "    max_depth=10,\n",
    "    max_features=0.75,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=2,\n",
    "    n_estimators=500,\n",
    "    warm_start=True,\n",
    "    oob_score=True    \n",
    ") \"\"\"\n",
    "\n",
    "# model = KNeighborsClassifier(n_neighbors=11 )\n",
    "\n",
    "\"\"\" model = MLPClassifier(\n",
    "    hidden_layer_sizes=(10, 8),  # Two hidden layers with 5 and 4 neurons\n",
    "    activation='relu',           # Activation function for hidden layers\n",
    "    solver='adam',               # Optimizer\n",
    "    max_iter=250,                # Maximum iterations\n",
    "    random_state=42,              # For reproducibility\n",
    "    alpha = 0.0001,\n",
    "    batch_size = 64,\n",
    "    learning_rate='adaptive',\n",
    "    learning_rate_init=0.001  \n",
    ") \"\"\"\n",
    "\n",
    "#model = SVC(kernel=\"rbf\", C=1, gamma=\"scale\", decision_function_shape=\"ovr\")\n",
    "\n",
    "\"\"\" model = XGBClassifier(\n",
    "    random_state = 42,\n",
    "    learning_rate=0.2\n",
    ") \"\"\"\n",
    "\n",
    "\"\"\" model = HistGradientBoostingClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=3, \n",
    "    max_iter=400\n",
    ") \"\"\"\n",
    "\n",
    "\"\"\" model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "# For RandomForestClassifier\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Pair each feature importance with the feature name\n",
    "feature_names = X.columns\n",
    "feature_importances_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "print(\"Feature Importances:\\n\", feature_importances_df.sort_values(by='Importance', ascending=False, ignore_index=True))\n",
    "\n",
    "# Calculate metrics on the training data to check for overfitting\n",
    "train_pred = model.predict(X_train)\n",
    "train_report = classification_report(y_train, train_pred)\n",
    "print(\"Training Classification Report:\\n\", train_report)\n",
    " \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
