{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Project II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from enum import IntEnum\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error, mean_absolute_error, mean_squared_error, accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR 2022\n",
      "features: 637\n",
      "entries: 27651\n",
      "YEAR 2023\n",
      "features: 647\n",
      "entries: 29522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['weight',\n",
       " 'height',\n",
       " 'pregnant',\n",
       " 'age',\n",
       " 'gender',\n",
       " 'education',\n",
       " 'single',\n",
       " 'owns_home',\n",
       " 'parent',\n",
       " 'depression',\n",
       " 'anxiety',\n",
       " 'poverty',\n",
       " 'health_status',\n",
       " 'life_sat',\n",
       " 'insurance',\n",
       " 'living_area',\n",
       " 'region',\n",
       " 'cancer',\n",
       " 'hypertension',\n",
       " 'cholesterol',\n",
       " 'asthma',\n",
       " 'race',\n",
       " 'medical_bill_worry']"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = {\n",
    "    \"WEIGHTLBTC_A\": \"weight\", #pounds\n",
    "    \"HEIGHTTC_A\": \"height\", #inches\n",
    "    \"PREGNOW_A\": \"pregnant\",\n",
    "    \"AGEP_A\": \"age\",\n",
    "    \"SEX_A\": \"gender\",\n",
    "    \"EDUCP_A\": \"education\",\n",
    "    \"MARITAL_A\": \"single\",\n",
    "    \"HOUTENURE_A\": \"owns_home\",\n",
    "    \"PARSTAT_A\": \"parent\",\n",
    "    \"DEPFREQ_A\": \"depression\",\n",
    "    \"ANXFREQ_A\": \"anxiety\",\n",
    "    \"POVRATTC_A\": \"poverty\",\n",
    "    \"PHSTAT_A\": \"health_status\",\n",
    "    \"LSATIS4_A\": \"life_sat\",\n",
    "    #\"DRK12MN_A\": \"alcohol\",\n",
    "    #\"SLPHOURS_A\": \"sleep\",\n",
    "    \"NOTCOV_A\": \"insurance\",\n",
    "    \"URBRRL\": \"living_area\",\n",
    "    \"REGION\": \"region\",\n",
    "    \"CANEV_A\": \"cancer\",\n",
    "    \"HYPEV_A\": \"hypertension\",\n",
    "    \"CHLEV_A\": \"cholesterol\",\n",
    "    \"ASEV_A\": \"asthma\",\n",
    "    \"RACEALLP_A\": \"race\",\n",
    "    \"PAYWORRY_A\": \"medical_bill_worry\"\n",
    "}\n",
    "\n",
    "dataframes = []\n",
    "for i in [2, 3]:\n",
    "    df = pd.read_csv(f\"../data/adult2{i}.csv\", sep=\",\")\n",
    "    dataframes.append(df)\n",
    "    print(f\"YEAR 202{i}\\nfeatures: {len(df.columns)}\\nentries: {len(df)}\")\n",
    "    for attr in attributes.keys():\n",
    "        try:\n",
    "            (f\"{attr}: {df[attr].unique()[:(min(10, len(df[attr].unique())))]}\")\n",
    "        except:\n",
    "            print(f\"missing {attr} for 202{i}\")\n",
    "df = pd.concat(dataframes)\n",
    "df = df.loc[:, list(attributes.keys())]\n",
    "df.rename(mapper=attributes, inplace=True, axis=1)\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"weight\"] <= 299]\n",
    "df = df[df[\"height\"] <= 76]\n",
    "df = df[((df[\"pregnant\"] == 2) | (df[\"gender\"] == 1))]\n",
    "df = df[df[\"age\"] <= 84]\n",
    "df = df[df[\"gender\"] <= 2]\n",
    "df = df[df[\"education\"] <= 10]\n",
    "df = df[df[\"single\"] <= 3]\n",
    "df = df[df[\"owns_home\"] <= 3]\n",
    "df = df[df[\"parent\"] <= 3]\n",
    "df = df[df[\"depression\"] <= 5]\n",
    "df = df[df[\"anxiety\"] <= 5]\n",
    "df = df[df[\"poverty\"] < 11]\n",
    "df = df[df[\"health_status\"] < 6]\n",
    "df = df[df[\"life_sat\"] < 5]\n",
    "#df = df[df[\"alcohol\"] < 366]\n",
    "#df = df[df[\"sleep\"] < 25]\n",
    "df = df[df[\"insurance\"] <= 2]\n",
    "# living area is good as it is\n",
    "# region too\n",
    "df = df[df[\"cancer\"] <= 2]\n",
    "df = df[df[\"hypertension\"] <= 2]\n",
    "df = df[df[\"cholesterol\"] <= 2]\n",
    "df = df[df[\"asthma\"] <= 2]\n",
    "df = df[df[\"race\"] <= 6]\n",
    "df = df[df[\"medical_bill_worry\"] <= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI calculation\n",
    "POUND_TO_KG = 0.453592\n",
    "INCH_TO_M = 0.0254\n",
    "df[\"weight\"] = df[\"weight\"] * POUND_TO_KG\n",
    "df[\"height\"] = df[\"height\"] * INCH_TO_M\n",
    "df[\"bmi\"] = df[\"weight\"] / df[\"height\"] ** 2\n",
    "\n",
    "del df[\"weight\"]\n",
    "del df[\"height\"]\n",
    "del df[\"pregnant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_cluster_number(df: pd.DataFrame, feature: str, k_number: int) -> int:\n",
    "    inertia = []\n",
    "    k_values = np.arange(1, k_number+1)\n",
    "\n",
    "    for k in k_values:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(df[[feature]])\n",
    "        inertia.append(kmeans.inertia_)\n",
    "\n",
    "    knee_locator = KneeLocator(k_values, inertia, curve='convex', direction='decreasing')\n",
    "    k = knee_locator.knee\n",
    "\n",
    "\n",
    "    \"\"\"fig, ax = plt.subplots(1, figsize=(8, 6))\n",
    "    ax.plot(k_values, inertia, marker='o')\n",
    "    ax.set(xlabel='Number of clusters (k)', ylabel='Inertia', title=f'Elbow Method for Optimal k for {feature}')\n",
    "    ax.axvline(x=elbow_point, c=\"red\")\n",
    "    ax.set_xticks(k_values) \"\"\"\n",
    "\n",
    "    return k, k_values, inertia\n",
    "\n",
    "def plot_cluster(df: pd.DataFrame, feature:str, k_values: np.ndarray, inertia: np.ndarray, k: int):\n",
    "    fig, axs = plt.subplots(2, figsize=(8, 6))\n",
    "    axs[0].plot(k_values, inertia, marker='o')\n",
    "    axs[0].set(xlabel='Number of clusters (k)', ylabel='Inertia', title=f'Elbow Method for Optimal k for {feature}')\n",
    "    axs[0].axvline(x=k, c=\"red\")\n",
    "    axs[0].set_xticks(k_values)\n",
    "\n",
    "    axs[1].scatter(df[feature], df[f'{feature}_cat'], c=df[f'{feature}_cat'], cmap='viridis')\n",
    "    axs[1].set_title(f\"{feature} Categories using K-Means Clustering\")\n",
    "    axs[1].set_xlabel(feature)\n",
    "    axs[1].set_ylabel(\"Category\")\n",
    "\n",
    "    \n",
    "CONTINUOUS_FEATURES = [\"age\", \"bmi\", \"poverty\"]\n",
    "for feature in CONTINUOUS_FEATURES:\n",
    "    k, k_values, inertia = get_optimal_cluster_number(df, feature, 10)\n",
    "    kmeans = KMeans(n_clusters=k, n_init=5, random_state=42)\n",
    "    df[f\"{feature}_cat\"] = kmeans.fit_predict(df[[feature]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regrouping\n",
    "\n",
    "\"\"\"\n",
    "EDUCATION\n",
    "00 (no edu), 01 (no hs), 02 (no diploma): no_hs\n",
    "03 (ged), 04 (hs), 05 (no deg): highschool\n",
    "06 (occupational deg), 07 (academic deg), 08 (bsc): bachelor\n",
    "09 (msc): masters\n",
    "10 (phd): phd\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "MARITAL status:\n",
    "03: single\n",
    "01 (married) 2 (cohabiting): not\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "parent\n",
    "01: parent\n",
    "02 (in famility but not) 03 (not in family): not\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def invert_encoding_order(df: pd.DataFrame, feature: str) -> None:\n",
    "    \"\"\"Reorders the encoding of a categorical variable, \n",
    "    so that the lowest values are encoded 0 and higher ones ascending from here.\"\"\"\n",
    "    df[feature] = df[feature].max() - df[feature]\n",
    "\n",
    "def offset_encoding_to_zero(df: pd.DataFrame, feature: str) -> None:\n",
    "    \"\"\"Re-encodes `1` and `2` category labels into `0` and `1`\"\"\"\n",
    "    df[feature] = df[feature] - 1\n",
    "\n",
    "\n",
    "offset_encoding_to_zero(df, \"gender\") \n",
    "\n",
    "class EduLevel(IntEnum):\n",
    "    NO_HIGHSCHOOL = 0\n",
    "    HIGHSCHOOL = 1\n",
    "    BACHELORS = 2\n",
    "    MASTERS = 3\n",
    "    PHD = 4\n",
    "    \n",
    "df[\"education\"] = df[\"education\"].replace({\n",
    "    1: EduLevel.NO_HIGHSCHOOL,\n",
    "    2: EduLevel.NO_HIGHSCHOOL,\n",
    "    3: EduLevel.HIGHSCHOOL,\n",
    "    4: EduLevel.HIGHSCHOOL,\n",
    "    5: EduLevel.HIGHSCHOOL,\n",
    "    6: EduLevel.BACHELORS,\n",
    "    7: EduLevel.BACHELORS,\n",
    "    8: EduLevel.BACHELORS,\n",
    "    9: EduLevel.MASTERS,\n",
    "    10: EduLevel.PHD\n",
    "})\n",
    "\n",
    "df[\"single\"] = df[\"single\"].replace({\n",
    "    1: 0,\n",
    "    2: 0,\n",
    "    3: 1\n",
    "})\n",
    "\n",
    "df[\"owns_home\"] = df[\"owns_home\"].replace({\n",
    "    1: 1,\n",
    "    2: 0,\n",
    "    3: 0,\n",
    "})\n",
    "\n",
    "df[\"parent\"] = df[\"parent\"].replace({\n",
    "    1: 1,\n",
    "    2: 0,\n",
    "    3: 0\n",
    "})\n",
    "\n",
    "\n",
    "invert_encoding_order(df, \"depression\")\n",
    "\n",
    "invert_encoding_order(df, \"anxiety\")\n",
    "\n",
    "invert_encoding_order(df, \"health_status\")\n",
    "\n",
    "invert_encoding_order(df, \"life_sat\")\n",
    "\n",
    "offset_encoding_to_zero(df, \"insurance\") \n",
    "\n",
    "invert_encoding_order(df, \"living_area\")\n",
    "\n",
    "offset_encoding_to_zero(df, \"region\") \n",
    "\n",
    "invert_encoding_order(df, \"cancer\")\n",
    "\n",
    "invert_encoding_order(df, \"hypertension\")\n",
    "\n",
    "invert_encoding_order(df, \"cholesterol\")\n",
    "\n",
    "invert_encoding_order(df, \"asthma\")\n",
    "\n",
    "offset_encoding_to_zero(df, \"race\") \n",
    "\n",
    "invert_encoding_order(df, \"medical_bill_worry\")\n",
    "\n",
    "df[\"age_cat\"] = df[\"age_cat\"].replace({\n",
    "    1: 0,\n",
    "    2: 1,\n",
    "    0: 2,\n",
    "})\n",
    "\n",
    "df[\"bmi_cat\"] = df[\"bmi_cat\"].replace({\n",
    "    2: 0,\n",
    "    0: 1,\n",
    "    1: 2,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(CONTINUOUS_FEATURES, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crosstables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' target = \"anxiety\"\\n\\nfor f in df.columns.values:\\n    tab = pd.crosstab(df[f], df[target], normalize=\"index\") * 100\\n    plt.figure(figsize=(6, 3))\\n    sns.heatmap(tab, fmt=\\'.2f\\', cmap=\\'coolwarm\\', annot=True)\\n    plt.show() '"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" target = \"anxiety\"\n",
    "\n",
    "for f in df.columns.values:\n",
    "    tab = pd.crosstab(df[f], df[target], normalize=\"index\") * 100\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    sns.heatmap(tab, fmt='.2f', cmap='coolwarm', annot=True)\n",
    "    plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-square tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               feature           chi              p\n",
      "0           depression  15793.186491   0.000000e+00\n",
      "1              age_cat   1425.727603  1.823056e-307\n",
      "2   medical_bill_worry   1251.239725  1.240938e-269\n",
      "3               gender   1104.225585  9.189134e-238\n",
      "4        health_status    361.803253   4.957452e-77\n",
      "5               asthma    360.400786   9.956869e-77\n",
      "6             life_sat    345.419779   1.709514e-73\n",
      "7            education    198.090764   9.667944e-42\n",
      "8         hypertension    178.677826   1.433765e-37\n",
      "9            owns_home    155.439801   1.389187e-32\n",
      "10         poverty_cat    136.038180   1.989087e-28\n",
      "11              single    119.390361   7.208863e-25\n",
      "12         cholesterol    107.485402   2.501311e-22\n",
      "13              parent     99.974694   9.959406e-21\n",
      "14              cancer     98.369083   2.187737e-20\n",
      "15         living_area     66.011423   1.575264e-13\n",
      "16             bmi_cat     62.934506   7.004726e-13\n",
      "17                race     39.362905   5.861853e-08\n",
      "18           insurance      1.305928   8.603690e-01\n",
      "19              region      0.927628   9.205641e-01\n"
     ]
    }
   ],
   "source": [
    "X = df.drop([\"anxiety\"], axis=1)\n",
    "y = df['anxiety']\n",
    "\n",
    "chi2_scores, p_values = chi2(X, y)\n",
    "alpha = 0.05\n",
    "\n",
    "feature_names = X.columns\n",
    "results = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'chi': chi2_scores,\n",
    "    'p': p_values\n",
    "}).sort_values(by='p', ignore_index=True)\n",
    "\n",
    "print(results)\n",
    "\n",
    "significant_features = results[results[\"p\"] < alpha][\"feature\"].values\n",
    "insignificant_features =  results[results[\"p\"] >= alpha][\"feature\"].values\n",
    "\n",
    "df.drop(insignificant_features, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_columns = [column for column in significant_features if len(df[column].unique()) > 2] \n",
    "df = pd.get_dummies(df, columns=one_hot_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.74      0.63      1591\n",
      "           1       0.44      0.44      0.44      1650\n",
      "           2       0.24      0.12      0.16       678\n",
      "           3       0.37      0.34      0.35       910\n",
      "           4       0.57      0.48      0.52       789\n",
      "\n",
      "    accuracy                           0.48      5618\n",
      "   macro avg       0.43      0.42      0.42      5618\n",
      "weighted avg       0.45      0.48      0.46      5618\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop([\"anxiety\"], axis=1)\n",
    "y = df[\"anxiety\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\"\"\" model = RandomForestClassifier(\n",
    "    bootstrap=False,\n",
    "    random_state=42,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=None,\n",
    "    max_features=\"sqrt\",\n",
    "    min_samples_split=2,\n",
    "    n_estimators=500\n",
    ") \"\"\"\n",
    "\n",
    "# model = KNeighborsClassifier(n_neighbors=11 )\n",
    "\n",
    "\"\"\" model = MLPClassifier(\n",
    "    hidden_layer_sizes=(10, 8),  # Two hidden layers with 5 and 4 neurons\n",
    "    activation='relu',           # Activation function for hidden layers\n",
    "    solver='adam',               # Optimizer\n",
    "    max_iter=250,                # Maximum iterations\n",
    "    random_state=42,              # For reproducibility\n",
    "    alpha = 0.0001,\n",
    "    batch_size = 64,\n",
    "    learning_rate='adaptive',\n",
    "    learning_rate_init=0.001  \n",
    ") \"\"\"\n",
    "\n",
    "#model = SVC(kernel=\"rbf\", C=1, gamma=\"scale\", decision_function_shape=\"ovr\")\n",
    "\n",
    "\"\"\" model = XGBClassifier(\n",
    "    random_state = 42,\n",
    "    learning_rate=0.2\n",
    ") \"\"\"\n",
    "\n",
    "model = HistGradientBoostingClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=3, \n",
    "    max_iter=400\n",
    ")\n",
    "\n",
    "model.fit(X_resampled, y_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
